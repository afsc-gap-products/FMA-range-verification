```{r, echo=FALSE, include=FALSE}
RACE_rawlength  <- readr::read_csv(here::here("data", "specimen_data.csv"))
  # sqlQuery(channel,query = paste0("SELECT * FROM RACE_DATA.V_EXTRACT_FINAL_LENGTHS A WHERE ((A.species_code = ",{{RACE}},"))"))

FMA_rawlength  <- readr::read_csv(here::here("data", "fma_l_data.csv"))
  # sqlQuery(channel,query = paste0("SELECT species_code, length, frequency  FROM NORPAC.ATL_LENGTH WHERE ((species_code = ",{{FMA}},"))"))

RACE_rawlength <- RACE_rawlength %>% filter(species_code == {{RACE}})
FMA_rawlength <- FMA_rawlength %>% filter(species == {{FMA}})


evaltf <- ifelse(nrow(RACE_rawlength) > 0, TRUE, FALSE)

str0 <- "This species does not have lengths in the database"

evaltf <- ifelse(nrow(FMA_rawlength) > 0, TRUE, FALSE)

str1 <- "This species does not have lengths in the database"

```

```{r include=FALSE, eval=evaltf}
#| label: var-{{RACE}}-{{NAME}}
RACE_rawlength2 <-  RACE_rawlength %>%
                    select(species_code, frequency, var, val) %>%
                    filter(var == "length", species_code == {{RACE}}) %>%
                    na.omit(RACE_rawlength$val) %>% 
                    rename("length" = "val")



RACE_rawlength2 <- RACE_rawlength2 %>% group_by(length) %>% mutate(total_lengths = sum(frequency)) # Total for each length class


lbh <- RACE_rawlength2 %>% select(species_code, length, total_lengths)
lbh <- lbh[!duplicated(lbh$length),] # Remove duplicates
lbh$percent <- 100*(lbh$total_lengths/sum(lbh$total_lengths)) # Add percent column
lbh <- lbh[order(lbh$length),] # Order of increasing length
lbh$rolling <- zoo::rollmeanr(lbh$percent, k = 2, fill = NA)
lbh$rolling <- zoo::rollmeanr(lbh$percent, k = 2, fill = lbh$percent)


records <- formatC(x = sum(RACE_rawlength2$frequency), format = "f", digits = 0, big.mark = ",", drop0trailing = TRUE)

race.range <- filter(lbh)
# race.range <- filter(lbh, percent > 0.01) # filters out <0.01% before calculating min/max/95% interval

# race.range2 <- filter(lbh, rolling >0.0175)

race.stdmin <- min(race.range$length)/10
race.stdmax <- max(race.range$length)/10

# expand lengths dataset by freq, so that there is no freq column
temp <- lbh[rep(x = 1:nrow(lbh), lbh$total_lengths), ]
race.q2_5 <- quantile(x = temp$length, probs = 0.025, na.rm = TRUE)
race.q97_5 <- quantile(x = temp$length, probs = 0.975, na.rm = TRUE)

# add a getmode function
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

mode0 <- getmode(v = temp$length)
median0 <- median(x = temp$length, na.rm = TRUE)
mean0 <- mean(lbh$length, na.rm = TRUE)
  
# race.rollmin <- min(race.range2$length)/10
# race.rollmax <- max(race.range2$length)/10

str0 <- paste0("Number of Records since 2005: **", records,"**  
  
Minimum: **", race.stdmin," cm**  |  Maximum: **", race.stdmax," cm**  
95% Interval: **", (race.q2_5/10)," cm** to **", (race.q97_5/10)," cm**")

# Rolling Min: **", race.rollmin," cm**  |  Rolling Max: **", race.rollmax," cm**
```

```{r include=FALSE, eval=evaltf}
#| label: var-{{FMA}}-{{NAME}}
FMA_rawlength2 <-  FMA_rawlength %>%
                    select(species, frequency, length) %>%
                    filter(species == {{FMA}}) %>%
                    na.omit(FMA_rawlength)

FMA_rawlength2 <- FMA_rawlength2 %>% group_by(length) %>% mutate(total_lengths = sum(frequency)) # Total for each length class

atl <- FMA_rawlength2 %>% select(species, length, total_lengths)
atl <- atl[!duplicated(atl$length),] # Remove duplicates
atl$percent <- 100*(atl$total_lengths/sum(atl$total_lengths)) # Add percent column
atl <- atl[order(atl$length),] # Order of increasing length

fma.records <- formatC(x = sum(FMA_rawlength2$frequency), format = "f", digits = 0, big.mark = ",", drop0trailing = TRUE)

# --- include if you want min/max to initially ignore lengths that occur less than 0.01% of the entire dataset --- #
# fma.range <- filter(atl, percent > 0.01)

# --- include if rolling mean is preferred --- #
# atl$rolling <- zoo::rollmeanr(atl$percent, k = 2, fill = NA)
# atl$rolling <- zoo::rollmeanr(atl$percent, k = 2, fill = atl$percent)
# fma.range2 <- filter(atl, rolling >0.0175)

fma.stdmin <- min(atl$length)
fma.stdmax <- max(atl$length)

# expand lengths dataset by freq, so that there is no freq column
temp1 <- atl[rep(x = 1:nrow(atl), atl$total_lengths), ]
fma.q2_5 <- quantile(x = temp1$length, probs = 0.025, na.rm = TRUE)
fma.q97_5 <- quantile(x = temp1$length, probs = 0.975, na.rm = TRUE)

# add a getmode function
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

mode1 <- getmode(v = temp$length)
median1 <- median(x = temp1$length, na.rm = TRUE)
mean1 <- mean(atl$length, na.rm = TRUE)
  
# fma.rollmin <- min(fma.range2$length)
# fma.rollmax <- max(fma.range2$length)

str1 <- paste0("Number of Records since 2013: **", fma.records,"**  
  
Minimum: **", fma.stdmin," cm**  |  Maximum: **", fma.stdmax," cm**  
95% Interval: **", (fma.q2_5)," cm** to **", (fma.q97_5)," cm**")
# --- include if rolling mean is preferred --- #
# Rolling Min: **", fma.rollmin," cm**  |  Rolling Max: **", fma.rollmax," cm**
```

# species: {{NAME}}
#### RACE DATA
`r str0`

```{r, echo=FALSE, eval=evaltf}
#| label: fig-second-{{RACE}}
#| fig-cap: 'RACE database lengths for {{NAME}} lengths as a percentage of recorded individuals. The shaded area is within the 95th percent confidence interval. '

lbh <- lbh %>%
  mutate(area = (length >= race.q97_5 | length < race.q2_5))

# line0 <- data.frame(x = c(mode0, median0, mean0),
#                     label = c("mode", "median", "mean"))

# line0 <- data.frame(x = mean0)

ggplot(data = lbh, aes(x = length, y = percent)) + 
  # geom_vline(data = line0, mapping = aes(xintercept = x, color = label), linetype = "dashed", size = 3) +
  # geom_vline(data = line0, mapping = aes(xintercept = x), linetype = "dashed", linewidth = 0.75) +
  # scale_colour_brewer(palette = "Greys") +
  geom_line() + 
  ylab("Percentage (%)") + 
  scale_x_continuous(breaks=number_ticks(10)) + 
  xlab("length (mm)") +
  geom_ribbon(data = subset(lbh, !(length >= race.q97_5 | length <= race.q2_5)), 
              mapping = aes(ymax = percent), ymin = 0, fill = "blue", alpha = 0.25, show.legend = FALSE) +
  theme_bw()

```

\newpage

#### FMA DATA
`r str1`

```{r, echo=FALSE, eval=evaltf}
#| label: fig-second-{{FMA}}
#| fig-cap: 'FMA database lengths for {{NAME}} as a percentage of recorded individuals. The shaded area is within the 95th percent confidence interval. '

atl <- atl %>%
  mutate(area = (length >= fma.q97_5 | length < fma.q2_5))

# line1 <- data.frame(x = c(mode1, median1, mean1), 
#                     label = c("mode", "median", "mean"))

# line1 <- data.frame(x = mean1)

ggplot(data = atl, aes(x = length, y = percent)) + 
  # geom_vline(data = line1, mapping = aes(xintercept = x, color = label), linetype = "dashed", size = 3) +
  # geom_vline(data = line1, mapping = aes(xintercept = x), linetype = "dashed", linewidth = 0.75) +
  # scale_colour_brewer(palette = "Greys") +
  geom_line() + 
  ylab("Percentage (%)") + 
  scale_x_continuous(breaks=number_ticks(10)) + 
  xlab("length (cm)") +
  geom_ribbon(data = subset(atl, !(length >= fma.q97_5 | length <= fma.q2_5)), 
              mapping = aes(ymax = percent), ymin = 0, fill = "red", alpha = 0.25, show.legend = FALSE) +
  theme_bw()

```

\newpage

```{=tex}
\pagebreak
```